{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+/f3BwTZ04/Rfuoqxyvc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corso_AI_2023/blob/main/appello_26.6.2023/MetodiAI_Fis2023_ProvaPratica_26_6_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova Pratica e Recupero Esoneri - Metodi AI e Machine Learning per la fisica\n",
        "### 26.6.2023 - AA 2022/23 - Docente: S. Giagu\n",
        "\n",
        "\n",
        "> **Regole:**\n",
        "\n",
        "*   **tempo a disposizione:**\n",
        "* recupero esoneri 3h + 20' per scaricare il dataset / fare l'upload del notebook a fine esonero\n",
        "* prova completa 3.5h + 20' per scaricare il dataset / fare l'upload del notebook a fine esonero\n",
        "\n",
        "*   compilare con i vostri dati i campi della cella che segue e poi eseguire la cella verificando che i dati printati corrispondano. L'esecuzione della cella scarica anche il dataset necessario (~5-8' di tempo in media)\n",
        "*   risolvere i quesiti/compiti indicati nella cella *Descrizione del compito* realtivi alla tipologia di prova che si vuole sostenere (completa o recupero esonero) usando questo notebook\n",
        "*   una volta completato il compito sottomettere il notebook nel apposito folder sul sito e-learning del corso disponibile al link: <p>\n",
        "[consegna esonero](https://elearning.uniroma1.it/mod/assign/view.php?id=567940)<p>\n",
        "NOTA BENE: una volta sottomesso il notebook non sono più possibili ulteriori modifiche"
      ],
      "metadata": {
        "id": "YtBvhAL0XXMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Dati Personali\n",
        "import os\n",
        "\n",
        "Nome = 'Stefano'  #@param {type: \"string\"}\n",
        "Cognome = 'Giagu' #@param {type: \"string\"}\n",
        "NumeroMatricola = 12345678 #@param {type: \"number\"}\n",
        "TipologiaProva = \"Prova Completa\" #@param [\"Prova Completa\",\"Recupero 1 Esonero\", \"Recupero 2 Esonero\" ] {type: \"string\"}\n",
        "\n",
        "if NumeroMatricola == 12345678:\n",
        "  print('\\033[1;31m Inserisci il numero di matricola corretto!!!!')\n",
        "else:\n",
        "  print('Download dataset ...')\n",
        "  !wget http://giagu.web.cern.ch/giagu/CERN/data_sprite_10k.npz\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "xaDyGsh6YorW",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4dc278-0481-43cd-da39-8fcf7a5f05f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31m Inserisci il numero di matricola corretto!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrizione del compito:\n",
        "\n",
        "Viene fornito un dataset costituto da 10k immagini di \"folletti\" a colori RGB a 8bit con dimensione (64,64,3) in formato numpy compresso (*.npz*). Il nome dell'array numpy all'interno del file è \"*images*\".\n",
        "\n",
        "\n",
        "###È richiesto di risolvere i seguenti task:###\n",
        "\n",
        "**Per chi deve recuperare il primo esonero:**\n",
        "\n",
        "1.   leggere il vettore di immagini dal file *data_sprite_10k.npz*, e creare per ogni immagine due versioni corrotte da rumore usando la seguente funzione:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "def add_gauss_noise(images, sigma=0.1):\n",
        "\n",
        "  noise = np.random.normal(loc=0,scale=sigma,size=images.shape)\n",
        "  noisy = np.clip((images + noise),0,255)\n",
        "\n",
        "  return noisy.astype(np.int32)\n",
        "```\n",
        "\n",
        "> in cui per la prima versione *sigma* è pari alla deviazione standard delle intensità dei pixel nel campione di immagini (basso rumore), mentre per la seconda versione è pari a 3 volte la deviazione standard (alto rumore).\n",
        "\n",
        "2.   graficare 4 esempi di immagini affiancando immagine pulita, immagine con basso rumore e immagine con alto rumore.\n",
        "\n",
        "3.   allenare due modelli di denoising basati su *sklearn.neighbors.KNeighborsClassifier*, usando le prime 5k immagini del campione come training set, e le successive 3k immagini come validation set, usando come input le immagini a basso e ad alto rumore rispettivamente, e come label le immagini originali pulite (nota: si sfrutta il fatto che il valore dei pixel è un intero compreso tra 0 e 255 interpretabile come una tra le possibili 255 \"classi\" per un classificatore multiclasse.\n",
        "\n",
        "4. stimare le prestazioni dei modelli addestrati\n",
        "\n",
        "5. utilizzando le rimanenti 2k immagini calcolare:\n",
        "- l'MSE e il PSNR tra immagine rumorosa e quella pulita\n",
        "- l'MSE e il PSNR tra immagine denoised predetta dal classificatore e quella pulita\n",
        "Graficare l'istogramma delle due distribuzioni con diversi colori (separatamente per il caso a basso e a alto rumore) e intepretare i risultati ottenuti.\n",
        "\n",
        "> NOTA: PSNR definizione su [wikipedia](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio), algoritmo implementato nella libreria *skimage* in *skimage.metrics.peak_signal_noise_ratio* (installare la libreria con *!pip install scikit-image*\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto\n",
        "\n",
        "<p>\n",
        "-------------------------------------------------------------------------------\n",
        "<p>\n",
        "\n",
        "**Per chi deve recuperare il secondo esonero:**\n",
        "\n",
        "1.   leggere il vettore di immagini dal file *data_sprite_10k.npz*, e creare per ogni immagine due versioni corrotte da rumore usando la seguente funzione:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "def add_gauss_noise(images, sigma=0.1):\n",
        "\n",
        "  noise = np.random.normal(loc=0,scale=sigma,size=images.shape)\n",
        "  noisy = np.clip((images + noise),0,255)\n",
        "\n",
        "  return noisy.astype(np.int32)\n",
        "```\n",
        "\n",
        "> in cui per la prima versione *sigma* è pari alla deviazione standard delle intensità dei pixel nel campione di immagini (basso rumore), mentre per la seconda versione è pari a 3 volte la deviazione standard (alto rumore).\n",
        "\n",
        "2.   graficare 4 esempi di immagini affiancando immagine pulita, immagine con basso rumore e immagine con alto rumore.\n",
        "\n",
        "3.  allenare due modelli di denoiser basati su un Auto-Encoder convoluzionale, usando le prime 5k immagini del campione come training set, e le successive 3k immagini come validation set, usando come input le immagini a basso e ad alto rumore rispettivamente, e come label le immagini originali pulite (suggerimento: usare uno spazio latente di dimensione sufficiente $\\ge$ 5).\n",
        "\n",
        "4. stimare le prestazioni dei modelli addestrati\n",
        "\n",
        "5. utilizzando le rimanenti 2k immagini calcolare:\n",
        "- l'MSE e il PSNR tra immagine rumorosa e quella pulita\n",
        "- l'MSE e il PSNR tra immagine denoised predetta dal classificatore e quella pulita\n",
        "Graficare l'istogramma delle due distribuzioni con diversi colori (separatamente per il caso a basso e a alto rumore) e intepretare i risultati ottenuti.\n",
        "\n",
        "> NOTA: PSNR definizione su [wikipedia](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio), algoritmo implementato nella libreria *torchmetrics* in *torchmetrics.PeakSignalNoiseRatio e trochmetric.MeanSquaredError* (installare la libreria con *!pip install torchmetric*\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto\n",
        "\n",
        "<p>\n",
        "-------------------------------------------------------------------------------\n",
        "<p>\n",
        "\n",
        "**Per chi deve sostenere la prova completa:**\n",
        "\n",
        "1.   leggere il vettore di immagini dal file *data_sprite_10k.npz*, e creare per ogni immagine una versione corrotta (immagine rumorosa) da rumore usando la seguente funzione:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "def add_gauss_noise(images, sigma=0.1):\n",
        "\n",
        "  noise = np.random.normal(loc=0,scale=sigma,size=images.shape)\n",
        "  noisy = np.clip((images + noise),0,255)\n",
        "\n",
        "  return noisy.astype(np.int32)\n",
        "```\n",
        "\n",
        "> in cui *sigma* è pari alla deviazione standard delle intensità dei pixel nel campione di immagini.\n",
        "\n",
        "2.   graficare 4 esempi di immagini affiancando immagine pulita e immagine rumorosa.\n",
        "\n",
        "3.   allenare un modello di denoising basato su *sklearn.neighbors.KNeighborsClassifier*, usando le prime 5k immagini del campione come training set, e le successive 3k immagini come validation set, usando come input le immagini rumorose, e come label le immagini originali pulite (nota: si sfrutta il fatto che il valore dei pixel è un intero compreso tra 0 e 255 interpretabile come una tra le possibili 255 \"classi\" per un classificatore multiclasse.\n",
        "\n",
        "4. stimare le prestazioni del modello addestrato\n",
        "\n",
        "5.  allenare un modello di denoiser basato su un Auto-Encoder convoluzionale, usando le prime 5k immagini del campione come training set, e le successive 3k immagini come validation set, usando come input le immagini rumorose, e come label le immagini originali pulite (suggerimento: usare uno spazio latente di dimensione sufficiente $\\ge$ 5).\n",
        "\n",
        "6. stimare le prestazioni dei modelli addestrati\n",
        "\n",
        "7. utilizzando le rimanenti 2k immagini calcolare:\n",
        "- l'MSE e il PSNR tra immagine rumorosa e quella pulita\n",
        "- l'MSE e il PSNR tra immagine denoised predetta dal classificatore e quella pulita\n",
        "Graficare l'istogramma delle due distribuzioni con diversi colori (separatamente per il caso a basso e a alto rumore) e intepretare i risultati ottenuti.\n",
        "\n",
        "> NOTA: PSNR definizione su [wikipedia](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio), algoritmo implementato nella libreria *torchmetrics* in *torchmetrics.PeakSignalNoiseRatio e trochmetric.MeanSquaredError* (installare la libreria con *!pip install torchmetric*\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto"
      ],
      "metadata": {
        "id": "U2gdMj7cYwtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... codice"
      ],
      "metadata": {
        "id": "Bkj62466Nuf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}