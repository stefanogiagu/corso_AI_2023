{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OsS4d2CDapDMu6o4pLiRMWVcyFMJqvCq",
      "authorship_tag": "ABX9TyPs3jVeCcKrS0nVTNvmLHQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corso_AI_2023/blob/main/appello_12.7.2023/MetodiAI_Fis2023_ProvaPratica_12_7_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova Pratica e Recupero Esoneri - Metodi AI e Machine Learning per la fisica\n",
        "### 12.7.2023 - AA 2022/23 - Docente: S. Giagu\n",
        "\n",
        "\n",
        "> **Regole:**\n",
        "\n",
        "*   **tempo a disposizione:**\n",
        "* recupero esoneri 1.5h\n",
        "* prova completa 2h\n",
        "\n",
        "*   compilare con i vostri dati i campi della cella che segue e poi eseguire la cella verificando che i dati printati corrispondano. L'esecuzione della cella scarica anche il dataset necessario\n",
        "*   risolvere i quesiti/compiti indicati nella cella *Descrizione del compito* realtivi alla tipologia di prova che si vuole sostenere (completa o recupero esonero) usando questo notebook\n",
        "*   una volta completato il compito sottomettere il notebook nel apposito folder sul sito e-learning del corso disponibile al link: <p>\n",
        "[consegna esonero](https://elearning.uniroma1.it/mod/assign/view.php?id=569041)<p>\n",
        "NOTA BENE: una volta sottomesso il notebook non sono più possibili ulteriori modifiche"
      ],
      "metadata": {
        "id": "YtBvhAL0XXMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Dati Personali\n",
        "import os\n",
        "\n",
        "Nome = 'Stefano'  #@param {type: \"string\"}\n",
        "Cognome = 'Giagu' #@param {type: \"string\"}\n",
        "NumeroMatricola = 12345678 #@param {type: \"number\"}\n",
        "TipologiaProva = \"Prova Completa\" #@param [\"Prova Completa\",\"Recupero 1 Esonero\", \"Recupero 2 Esonero\" ] {type: \"string\"}\n",
        "\n",
        "if NumeroMatricola == 12345678:\n",
        "  print('\\033[1;31m Inserisci il numero di matricola corretto!!!!')\n",
        "else:\n",
        "  print('Download dataset ...')\n",
        "  !wget http://giagu.web.cern.ch/giagu/CERN/susy_sg.csv\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "xaDyGsh6YorW",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6041ef47-3fda-4a91-fe26-79ea9c072d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31m Inserisci il numero di matricola corretto!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrizione del compito:\n",
        "\n",
        "Viene fornito un dataset costituto da 400k decadimenti di particelle supersimmetriche misurate in un rivelatore al collider LHC. Il dataset è contenuto nel file *susy_sg.csv*, e contiene per ogni decadimento 9 fetaures di alto livello che lo descrivono (*'lepton 1 pT', 'lepton 1 eta', 'lepton 2 pT', 'lepton 2 eta','missing energy magnitude', 'R', 'M_Delta_R', 'dPhi_r_b','cos(theta_r1)'*)\n",
        "\n",
        "<p>\n",
        "<p>\n",
        "\n",
        "###È richiesto di risolvere i seguenti task:###\n",
        "\n",
        "**Per chi deve recuperare il primo esonero:**\n",
        "\n",
        "1.   leggere il dataset a analizzarne le caratteristiche che si ritengono più significative, plottando le distribuzioni delle osservabili e le loro correlazioni;\n",
        "\n",
        "2.   allenare un modello generativo basato su pde estimation con kernels, usando kernel gaussiani (usare: *sklearn.neighbors.KernelDensity*, in cui il pramatero di smoothing è indicato come *bandwidth*, e si possono generare campioni dalle distribuzioni apprese tramite il metodo *.sample(...)*), in modo che sia in grado di generare eventi in accordo alla distribuzione delle osservabili delle particele supersimmetriche;\n",
        "\n",
        "3. generare 10k eventi con il modello KernelDensity e plottare istogrammi per ognuna delle osservabili vere con sovrapposta la distribuzione generata dal modello KernelDensity;\n",
        "\n",
        "4. stimare quantitativamente in modo opportuno la qualità delle distribuzioni generate dal modello KernelDensity rispetto a quelle vere;\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "<p>\n",
        "-------------------------------------------------------------------------------\n",
        "<p>\n",
        "\n",
        "**Per chi deve recuperare il secondo esonero:**\n",
        "\n",
        "1.   leggere il dataset a analizzarne le caratteristiche che si ritengono più significative, plottando le distribuzioni delle osservabili e le loro correlazioni;\n",
        "\n",
        "2.   allenare un modello generativo basato su Vun Variational Auto Encoder in modo che sia in grado di generare eventi in accordo alla distribuzione delle osservabili delle particele supersimmetriche;\n",
        "\n",
        "3. generare 10k eventi con il modello VAE e plottare istogrammi per ognuna delle osservabili vere con sovrapposta la distribuzione generata dal modello VAE;\n",
        "\n",
        "4. stimare quantitativamente in modo opportuno la qualità delle distribuzioni generate dal modello VAE rispetto a quelle vere;\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "<p>\n",
        "-------------------------------------------------------------------------------\n",
        "<p>\n",
        "\n",
        "**Per chi deve sostenere la prova completa:**\n",
        "\n",
        "1.   leggere il dataset a analizzarne le caratteristiche che si ritengono più significative, plottando le distribuzioni delle osservabili e le loro correlazioni;\n",
        "\n",
        "2.   allenare un modello generativo basato su pde estimation con kernels, usando kernel gaussiani (usare: *sklearn.neighbors.KernelDensity*, in cui il pramatero di smoothing è indicato come *bandwidth*, e si possono generare campioni dalle distribuzioni apprese tramite il metodo *.sample*), in modo che sia in grado di generare eventi in accordo alla distribuzione delle osservabili delle particele supersimmetriche;\n",
        "\n",
        "3. generare 10k eventi con il modello KernelDensity e plottare istogrammi per ognuna delle osservabili vere con sovrapposta la distribuzione generata dal modello KernelDensity;\n",
        "\n",
        "4.   allenare un modello generativo basato su un Variational Auto Encoder in modo che sia in grado di generare eventi in accordo alla distribuzione delle osservabili delle particele supersimmetriche;\n",
        "\n",
        "5. generare 10k eventi con il modello AVE e plottare istogrammi per ognuna delle osservabili vere con sovrapposta la distribuzione generata dal modello VAE;\n",
        "\n",
        "6. stimare quantitativamente in modo opportuno la qualità delle distribuzioni generate dal modello VAE rispetto a quelle vere;\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto."
      ],
      "metadata": {
        "id": "U2gdMj7cYwtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... codice"
      ],
      "metadata": {
        "id": "Bkj62466Nuf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}